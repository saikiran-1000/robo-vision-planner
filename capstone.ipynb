{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RoboVision Planner\n\n**Overview**  \nRoboVision Planner is a compact multi-agent system that converts an input image and a natural-language instruction into a step-by-step robot action plan. This notebook demonstrates the end-to-end pipeline using Google ADK concepts: VisionTool (tool), VisionAgent, PlannerAgent (LLM), Orchestrator, InMemorySessionService, and a small evaluation harness.\n\n","metadata":{}},{"cell_type":"code","source":"# --- INSTALLATION ---\n!pip install google-adk --upgrade > /dev/null 2>&1\n\nimport os\nimport json\nfrom typing import Any, Dict, List\nfrom datetime import datetime\nimport uuid\nimport base64\nimport asyncio\n\n# ADK Core Imports\nfrom google.genai import types\nfrom google.adk.agents import LlmAgent, Agent, SequentialAgent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import FunctionTool\nfrom google.adk.models.google_llm import Gemini\n\nprint(\"âœ… ADK Installed and Imported\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Authentiucation**","metadata":{}},{"cell_type":"code","source":"# --- API KEY SETUP ---\ntry:\n    from kaggle_secrets import UserSecretsClient\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"ðŸ” API Key Loaded Successfully\")\nexcept:\n    print(\"âš ï¸ Could not load API Key. Ensure it's set correctly.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Global Config**","metadata":{}},{"cell_type":"code","source":"# --- GLOBAL CONFIG ---\nretry_config = types.HttpRetryOptions(\n    attempts=5,\n    exp_base=7,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504]\n)\n\nsession_service = InMemorySessionService()\n\nGEMINI_MODEL = Gemini(\n    model_name=\"gemini-2.5-flash\",\n    retry_config=retry_config\n)\n\ndef pretty_print_json(data: Any):\n    print(json.dumps(data, indent=2, ensure_ascii=False))\n\nprint(\"âš™ï¸ Configuration Ready\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Vision Agent & Planner Agent\n\nWe implement:\n- **VisionAgent** â€” calls the VisionToolWrapper to extract a structured scene summary.\n- **PlannerAgent** â€” uses Gemini (or a heuristic fallback) to convert the scene summary and user instruction into a step-by-step plan.\n\n\n","metadata":{}},{"cell_type":"code","source":"# --- Agents (VisionAgent, PlannerAgent, Orchestrator) ---\n\n# Create VisionTool instance (uses GEMINI_MODEL if available)\nvision_tool = None\ntry:\n    vision_tool = VisionToolWrapper(gemini_model=GEMINI_MODEL, use_real=USE_REAL_VISION)\nexcept Exception as e:\n    logger.warning(\"Could not instantiate VisionToolWrapper cleanly: %s\", str(e))\n    vision_tool = VisionToolWrapper(gemini_model=None, use_real=False)\n\n# Helper: compact scene summary\ndef compact_scene(vision_result: Dict[str, Any]) -> Dict[str, Any]:\n    objs = vision_result.get('objects', [])\n    return {\n        'objects': [{'name': o.get('label'), 'bbox': o.get('bbox')} for o in objs],\n        'captions': vision_result.get('captions', [])\n    }\n\n# Planner helper: build prompt\ndef build_planner_prompt(instruction: str, scene_summary: Dict[str, Any]) -> str:\n    obj_names = ', '.join([o['name'] for o in scene_summary.get('objects', [])]) or \"none\"\n    prompt = textwrap.dedent(f\"\"\"\n    You are a robotics task planner. The user instruction is: \"{instruction}\".\n    The visible scene objects are: {obj_names}.\n    Provide a concise step-by-step robot action plan (3-8 steps). Reference objects exactly by name.\n    Output in plain text, steps numbered.\n    \"\"\").strip()\n    return prompt\n\n# Planner LLM call (tries Gemini via ADK; otherwise heuristic)\ndef call_planner_llm(prompt: str) -> str:\n    # Try real Gemini\n    try:\n        if GEMINI_MODEL:\n            resp = GEMINI_MODEL.generate(messages=[{\"role\":\"user\",\"content\":prompt}])\n            # Extract text in different possible fields\n            text = getattr(resp, \"text\", None) or getattr(resp, \"content\", None) or str(resp)\n            return text if isinstance(text, str) else json.dumps(text)\n    except Exception as e:\n        logger.warning(\"Planner LLM call failed: %s\", str(e))\n    # Fallback heuristic plan\n    # A simple rule-based generator based on objects in prompt\n    objs = []\n    if \"The visible scene objects are:\" in prompt:\n        try:\n            objs_part = prompt.split(\"The visible scene objects are:\")[1].split(\".\")[0]\n            objs = [o.strip() for o in objs_part.split(',') if o.strip() and o.strip() != \"none\"]\n        except Exception:\n            objs = []\n    steps = []\n    if objs:\n        target = objs[0]\n        steps = [\n            \"1. Localize the target object in the workspace using vision.\",\n            f\"2. Navigate the manipulator to the location of {target}.\",\n            f\"3. Execute a secure grasp of {target}.\",\n            \"4. Move to the target placement location.\",\n            \"5. Release the object and verify placement visually.\",\n            \"6. Return to a safe standby position.\"\n        ]\n    else:\n        steps = [\n            \"1. No recognizable objects detected. Perform a 360-degree scan.\",\n            \"2. Report nothing found or wait for user clarification.\"\n        ]\n    return \"\\n\".join(steps)\n\n# ADK-style agents (simple classes compatible with InMemoryRunner)\nclass VisionAgent(Agent):\n    def __init__(self, tool: VisionToolWrapper):\n        super().__init__(name=\"VisionAgent\")\n        self.tool = tool\n\n    def run(self, message: Dict[str, Any], ctx: Dict[str, Any]) -> Dict[str, Any]:\n        # Expect attachments: {'image': path_or_url}\n        attachments = ctx.get('attachments', {})\n        image = attachments.get('image') or INPUT_IMAGE_PATH\n        logger.info(\"VisionAgent: running detection on image=%s\", str(image))\n        vision_out = self.tool.detect(image)\n        scene = compact_scene(vision_out)\n        return {'vision_raw': vision_out, 'scene_summary': scene}\n\nclass PlannerAgent(Agent):\n    def __init__(self):\n        super().__init__(name=\"PlannerAgent\")\n\n    def run(self, message: Dict[str, Any], ctx: Dict[str, Any]) -> Dict[str, Any]:\n        instruction = message.get('instruction', '')\n        scene = message.get('scene_summary', {})\n        prompt = build_planner_prompt(instruction, scene)\n        logger.info(\"PlannerAgent: calling LLM for planning.\")\n        plan_text = call_planner_llm(prompt)\n        # Sanity: check referenced objects\n        obj_names = [o['name'] for o in scene.get('objects', [])]\n        referenced = [n for n in obj_names if n.lower() in plan_text.lower()]\n        missing = [n for n in obj_names if n not in referenced]\n        return {'plan': plan_text, 'referenced_objects': referenced, 'missing_objects': missing}\n\nclass OrchestratorAgent(Agent):\n    def __init__(self, vision_agent: VisionAgent, planner_agent: PlannerAgent, memory: MemoryBank):\n        super().__init__(name=\"Orchestrator\")\n        self.vision_agent = vision_agent\n        self.planner_agent = planner_agent\n        self.memory = memory\n\n    def run(self, message: Dict[str, Any], ctx: Dict[str, Any]) -> Dict[str, Any]:\n        instruction = message.get('instruction', '')\n        logger.info(\"Orchestrator: starting pipeline for instruction: %s\", instruction)\n        # Vision\n        vision_res = self.vision_agent.run(message, ctx)\n        # Planning\n        planner_input = {'instruction': instruction, 'scene_summary': vision_res['scene_summary']}\n        planner_res = self.planner_agent.run(planner_input, ctx)\n        record = {\n            'id': str(uuid.uuid4()),\n            'timestamp': datetime.utcnow().isoformat(),\n            'instruction': instruction,\n            'vision': vision_res,\n            'plan': planner_res\n        }\n        self.memory.add(record)\n        logger.info(\"Orchestrator: pipeline finished and stored in memory.\")\n        return record\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}